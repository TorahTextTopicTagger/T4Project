{"cells":[{"cell_type":"markdown","metadata":{"id":"A3EAg1qpk5_E"},"source":["# Constants"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r3HLP6gfPjsP"},"outputs":[],"source":["TOPIC = 'תורה'\n","CLEANED_DATA_PATH = '../../Data/Cleaned Data/good_df.json'\n","BEREL_BASE_PATH = '../../Models/Saved_Models/Transformers/BEREL_base'"]},{"cell_type":"markdown","metadata":{"id":"rPh9coOPpsQ5"},"source":["# Setup"]},{"cell_type":"markdown","metadata":{"id":"3yHwMsLDpsTC"},"source":["## Groundwork Installations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wLxVS_nGCVgW"},"outputs":[],"source":["import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BOStmWRiOp3L"},"outputs":[],"source":["good_df = pd.read_json(CLEANED_DATA_PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ctcPKEsOsu_"},"outputs":[],"source":["good_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j1ifGivoPL3_"},"outputs":[],"source":["! pip install transformers datasets"]},{"cell_type":"markdown","metadata":{"id":"9gPqKwN1p6g_"},"source":["## Setup Topic Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZO0oV2M-Of3c"},"outputs":[],"source":["def create_single_topic_df(good_df, topic, random_state=613):\n","  using = good_df.copy()\n","  using['label'] = np.where(using['topic']==(topic), 1,0)\n","  positive = using[using['label']==1]\n","  using = using[using['text'].isin(positive['text']) == False]\n","  negative = using.sample(len(positive.index), random_state=random_state)\n","  combined = pd.concat([positive, negative], axis=0)\n","  combined.drop(['pm_ref', 'topic'], axis=1, inplace=True)\n","  return combined"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-iY8eaD5PTs-"},"outputs":[],"source":["from datasets import Dataset\n","from sklearn.model_selection import train_test_split\n","single_topic_df = create_single_topic_df(good_df, TOPIC)\n","train_df, eval_df = train_test_split(single_topic_df, test_size=0.2, random_state=613)\n","train_dataset = Dataset.from_pandas(train_df)\n","eval_dataset = Dataset.from_pandas(eval_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UPx_gXVaWJoR"},"outputs":[],"source":["len(train_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r_XMp5Y2acKi"},"outputs":[],"source":["len(eval_dataset)"]},{"cell_type":"markdown","metadata":{"id":"HIelw-Ixpn_E"},"source":["# AlephBert"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mLIRAtmWRrJ4"},"outputs":[],"source":["from transformers import BertTokenizerFast\n","\n","alephbert_tokenizer = BertTokenizerFast.from_pretrained('onlplab/alephbert-base')\n","\n","def tokenize_function(examples):\n","    return alephbert_tokenizer(examples['text'], padding=\"max_length\", truncation=True)\n","\n","tokenized_train = train_dataset.map(tokenize_function, batched=True)\n","tokenized_eval = eval_dataset.map(tokenize_function, batched=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8X3XK6N9Sq6f"},"outputs":[],"source":["from transformers import AutoModelForSequenceClassification\n","\n","model = AutoModelForSequenceClassification.from_pretrained('onlplab/alephbert-base', num_labels=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GTDVg06JT4eY"},"outputs":[],"source":["model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3gF0_Yb8NRB6"},"outputs":[],"source":["from transformers import TrainingArguments\n","\n","training_args = TrainingArguments(output_dir=\"test_trainer\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TG3Nqwx_NRB7"},"outputs":[],"source":["import numpy as np\n","import evaluate\n","\n","metric = evaluate.load(\"accuracy\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IK4vOm2YNRB8"},"outputs":[],"source":["def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oyUWZf5yNRB9"},"outputs":[],"source":["from transformers import TrainingArguments, Trainer\n","\n","training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q94Eli50NRB-"},"outputs":[],"source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_train,\n","    eval_dataset=tokenized_eval,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3zgxK4ITNRB_"},"outputs":[],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Et_mzqb0eQG_"},"outputs":[],"source":["trainer.evaluate()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F-7xDdO5EoXt"},"outputs":[],"source":["trainer.save_model(\"./alephBERT_model\")"]},{"cell_type":"markdown","metadata":{"id":"0_bbarpQpg8Y"},"source":["# BEREL"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IuEaiLgup0sd"},"outputs":[],"source":["from rabtokenizer import RabbinicTokenizer\n","from transformers import BertTokenizer, BertForMaskedLM\n","import os\n","\n","berel_tokenizer = RabbinicTokenizer(BertTokenizer.from_pretrained(os.path.join(BEREL_BASE_PATH, 'vocab.txt'), model_max_length=512))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5nw1cj0xvdj5"},"outputs":[],"source":["def tokenize_function(examples):\n","    return berel_tokenizer(examples['text'], padding='max_length', truncation=True)\n","\n","tokenized_train = train_dataset.map(tokenize_function, batched=True)\n","tokenized_eval = eval_dataset.map(tokenize_function, batched=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tLwtjEy8t45w"},"outputs":[],"source":["model = AutoModelForSequenceClassification.from_pretrained(BEREL_BASE_PATH, num_labels=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TwdzLeSmvhov"},"outputs":[],"source":["model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qz9sEl8Xva4G"},"outputs":[],"source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_train,\n","    eval_dataset=tokenized_eval,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1yFgSdSowL6a"},"outputs":[],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hJSPvMqoztgL"},"outputs":[],"source":["trainer.evaluate()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Azq79aXJEt52"},"outputs":[],"source":["trainer.save_model(\"./BEREL_model\")"]},{"cell_type":"markdown","metadata":{"id":"ES4Tc8Ot0Bkk"},"source":["# HeBERT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IuB9EmnS0Bkl"},"outputs":[],"source":["from transformers import AutoTokenizer\n","heBERT_tokenizer = AutoTokenizer.from_pretrained(\"avichr/heBERT\", model_max_length=512)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d8C6pwnT0Bkl"},"outputs":[],"source":["def tokenize_function(examples):\n","    return heBERT_tokenizer(examples['text'], padding='max_length', truncation=True)\n","\n","tokenized_train = train_dataset.map(tokenize_function, batched=True)\n","tokenized_eval = eval_dataset.map(tokenize_function, batched=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MiaFY1EE0Bkl"},"outputs":[],"source":["model = AutoModelForSequenceClassification.from_pretrained('avichr/heBERT', num_labels=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vAypV5260Bkl"},"outputs":[],"source":["model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SoJOF_NW0Bkl"},"outputs":[],"source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_train,\n","    eval_dataset=tokenized_eval,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vk_4zPoI0Bkl"},"outputs":[],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s32-El0K0Bkm"},"outputs":[],"source":["trainer.evaluate()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4HhcPdhtEw5N"},"outputs":[],"source":["trainer.save_model(\"./heBERT_model\")"]},{"cell_type":"markdown","metadata":{"id":"EXNb3layLLeL"},"source":["# FOR COLAB -- Download Saved Models from Session Storage"]},{"cell_type":"markdown","metadata":{"id":"NcoTO7mPj1Qx"},"source":["If running this script in Google Colab, the files that were saved above to session storage will be too big to download directly, but they can be moved into your Google Drive. Below is a way to do that, saving to drive as one zipped file containing all 3 models:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NKqIX1CALQJm"},"outputs":[],"source":["!zip -r /content/all_models.zip /content/BEREL_model /content/alephBERT_model /content/heBERT_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j9hQAkaPQpx3"},"outputs":[],"source":["import shutil\n","DRIVE_DESTINATION = #<your desired destination directory in your drive for the zip file>\n","shutil.copyfile(\n","    '/content/all_models.zip',\n","    f'{DRIVE_DESTINATION}/{TOPIC}_saved_models')"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"}},"nbformat":4,"nbformat_minor":0}