{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"LnFXe_yanzas"},"source":["# Instructions"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"j8MiFev2nzav"},"source":["This demo shows how you can load our fine-tuned transformer models for a given topic, define some example text to feed through the models, and see the inferences each model makes."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"zSBROi56nzaw"},"source":["# Code"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"9CvoCaulnzaw"},"source":["## Loading Models"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"AQ2LuETLnzax"},"source":["First, choose the topic you'd which the models will classify for (in this example we choose prayer -- \"תפילה\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XkHqO2jBnzax"},"outputs":[],"source":["# CHOOSE YOUR TOPIC, options are ישראל, למוד, תורה, תפלה, תשובה\n","TOPIC = 'תפלה'"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"8OWLhR_znzay"},"source":["Next we define the paths to the files we'll need for our models:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nwqy6tF4nf3V"},"outputs":[],"source":["topic_to_english = {\n","    'ישראל' : 'yisrael',\n","    'תורה' : 'torah',\n","    'תשובה' : 'teshuva',\n","    'תפלה' : 'tefillah',\n","    'למוד' : 'limmud'\n","}\n","def get_transformer_model_path(topic, base_model_name):\n","  return f't4-project/{topic_to_english[topic]}-{base_model_name}'\n","\n","BEREL_BASE_PATH = 't4-project/BEREL-base'"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"J5a0MCU0nzaz"},"source":["Next we install the huggingface transformers library"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZTD0mcFohCyi","outputId":"bbccf36b-d05c-4921-a3e0-3050c283df69"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.27.1)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (23.0)\n","Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.8.0)\n","Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.64.1)\n","Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.23.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.14.1)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.28.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.13.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n","Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.1.0)\n","Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n","Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.1.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (1.26.12)\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip available: 22.3 -> 23.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["! pip install transformers"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"nMgPuaW-nza0"},"source":["And finally, we load the models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9GmA6D6RuaDp","outputId":"9628b6bc-8cda-4691-8a11-5e1dc72d1b17"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from transformers import AutoModelForSequenceClassification, TextClassificationPipeline\n","from transformers import BertTokenizerFast"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u1OeZP3fuaDq"},"outputs":[],"source":["from transformers import BertTokenizer\n","from rabtokenizer import RabbinicTokenizer\n","from transformers import AutoTokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200,"referenced_widgets":["eb889b3606f44fb790f1cf9343f4a564","3f944b3a95a243f3a4e9c830fd6e00f9","c5cb1fc39d24429183071183c67c1fb6","eace89c1254d41d2a036c348b6efc41f","19413082ba9d41b5a36762c933bf5979","aa27d2a8fd0b439080f9f9afb75e7d6a","13a104558ae64718be9fad00bfa53fb4","496d1f4d116b452d9869a23f6a33323b","bf762939f53d43febfe1958ffb6b0524","a0768d58a3424668ace3ec78de69a7ec","52f0708ab0ea4ec59c46ddefb7fc1e09","cdfb959b84eb4adeb65fcc2233567d7f","5ad5c8193fe04f3c8a89b6b4769ccac1","da86d97b22b648bdb16f1f6cb9a9f8a2","386497a6e85b48d382a3a6bf1416197a","5c4bb36e23b549faa6cb37b13c057e81","6e9445e7bfb64cf4aea0583b16479337","ca5d01680198484c845e8f6e03c0ca0b","ab681961a1c6405590aeea3204f4cec0","59061ad58bcd4839be422a376666de5a","c17a2d34c4dd437e94d4ad231e06ce55","aabf76acd18a49e58f65f58a2674c33a","08dd5d91739a4c269a54c1f7bcabe8f4","92b5f2c93e1b476cb46ab29efb6c2f62","16cfbbbfa7c0441f963e5ef45109a449","bc33f575a6da41e5afbef4374426b40f","bff83cbfb08d475cbaedde81dfda73ab","f7f6ef8569bb40d8a6d6771d9d80285e","cc58988ed2c0456f866df942a6a9ebda","dd7cd599dbc84034888b419f8fead122","bf4457cc60764f35b4178016169b46aa","d60643c9d2d946d18ec23ac4980b4e91","65f26b7f658046a9960055c5a3b40591","e6f2578b0eeb4bc0ab1aa5555a818d41","9d629e96db84426f8ecc1964382e726d","a97c55b7787c43d181557b22310d34da","c25df6498c6d47df886a2dbf75a51527","931451164a2846579e08843f646b97e9","57bdbda77dcb44de94e9fab7fc2746ec","5a4685f98a7549d8b42324e725a45253","5a72ad685ab64daeab63d3767e16ca9e","785067c727b34f39860d9fc232e5d707","e7c425b8fe2349b69f0a282ee0056a2f","4b8dee1bcc954b53a5d78137841d5b8a"]},"id":"DwabAreCuaDq","outputId":"d213aee6-8086-40ff-d6d1-d00dddc91c07"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n","  warnings.warn(\n"]}],"source":["alephBERT_tokenizer = BertTokenizerFast.from_pretrained('onlplab/alephbert-base')\n","alephBERT_loaded_model = AutoModelForSequenceClassification.from_pretrained(get_transformer_model_path(TOPIC, 'alephBERT'), num_labels=2)\n","alephBERT_pipe = TextClassificationPipeline(model=alephBERT_loaded_model, tokenizer=alephBERT_tokenizer, return_all_scores=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HFBxr6AYuaDq","outputId":"7c7075d5-003b-47df-fa80-31f039dbd131"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1706: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n","  warnings.warn(\n","c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n","  warnings.warn(\n"]}],"source":["berel_loaded_model = AutoModelForSequenceClassification.from_pretrained(get_transformer_model_path(TOPIC, 'BEREL'), num_labels=2)\n","berel_tokenizer = RabbinicTokenizer(BertTokenizer.from_pretrained(BEREL_BASE_PATH, model_max_length=512))\n","berel_pipe =TextClassificationPipeline(model=berel_loaded_model, tokenizer=berel_tokenizer, return_all_scores=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["99127d5d78a34f198ade251268d87b30","aed9c45a4be4498db3e983cfdef82137","9ad9fedd294844ba9d80b888893a600e","568fcc110ade403cb6be0164446763e9","2719ec77be8f4227896313b5d7dd59df","0caf334537d944e58af939f0820e23fe","b447eacee9604814bdaab28af6d40389","b019e680f52942ce8e2cb210ae461c04","74fd286a39894e238053684078c36aac","8d7530cbadb2485abb3bda3e793c35eb","c11ec0968c11471585decf89c9753a80","b26a8570c31b4cd88edd557b173671e1","853025389aa84765821aedc4b22b4f4f","3164535cf35445e4aa20e03813cd33ed","8a37821daf5540c48a8f50dde7adbcbe","3d8208f337f246f58b4b1eac75f9e336","1120c1a109f64577ab1a4715d9fa8e23","3da1f58e696a4e22a9e04737aab6ba13","b4904e9327414fab81f17185030bfb2c","4b425f5aea754309866d07020fe26db6","c6d9ff1e05154c95baf9ab461c00e0d6","d3ba34f7cc47422b8994e1902277debe"]},"id":"zGom4N7DuaDr","outputId":"b7e6fa8c-b5ba-45c9-c600-8d48453b53c0"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading (…)lve/main/config.json: 100%|██████████| 505/505 [00:00<00:00, 524kB/s]\n","c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n","To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n","  warnings.warn(message)\n","Downloading (…)solve/main/vocab.txt: 100%|██████████| 299k/299k [00:00<00:00, 2.49MB/s]\n","c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n","  warnings.warn(\n"]}],"source":["heBERT_tokenizer = AutoTokenizer.from_pretrained(\"avichr/heBERT\", model_max_length=512)\n","heBERT_loaded_model = AutoModelForSequenceClassification.from_pretrained(get_transformer_model_path(TOPIC, 'heBERT'), num_labels=2)\n","heBERT_pipe = TextClassificationPipeline(model=heBERT_loaded_model, tokenizer=heBERT_tokenizer, return_all_scores=True)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"wfPTuWHZnza1"},"source":["## Inference"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"JDUEKib9nza1"},"source":["Here you can define any text as a string to feed into the models. For this example, we choose one sentence that is highly correlated with the topic (it translates to \"standing before the Holy One Blessed be He, and calling out with all of one's heart about one's troubles\") and one sentence that is not at all correlated (it translates to \"it is nothing more than frivolity and light-headedness, and a son of Torah should not engage in these matters\").\n","\n","Note that for the related sentence, we choose a sentence that does not contain the topic's word, and yet the models are able to deduce the relationship."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tofwLOvWnza2"},"outputs":[],"source":["is_topic_text = 'עומד לפני הקדוש ברוך הוא וצועק בלב שלם על צרותיו'\n","is_not_topic_text = 'אין זה אלא שחוק וקלות ראש, ואין לבן תורה לעסוק בענינים אלו'"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"LtF19Oz6nza2"},"source":["To read the predictions, see that we are shown the score for LABEL_0 which means \"not related to the topic,\" and LABEL_1 which means \"related to the topic"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cjYuni8OuaDr","outputId":"7289af6e-caa9-4355-e196-b671be687177"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model Predictions for a text that is tagged with the topic:\n"," [[{'label': 'LABEL_0', 'score': 0.015154956839978695}, {'label': 'LABEL_1', 'score': 0.9848451018333435}]]\n","Model Predictions for a text that is NOT tagged with the topic:\n"," [[{'label': 'LABEL_0', 'score': 0.9984642267227173}, {'label': 'LABEL_1', 'score': 0.0015357907395809889}]]\n"]}],"source":["print(f'Model Predictions for a text that is tagged with the topic:\\n {alephBERT_pipe(is_topic_text)}')\n","print(f'Model Predictions for a text that is NOT tagged with the topic:\\n {alephBERT_pipe(is_not_topic_text)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SeMrlUanuaDs","outputId":"c4ee01cb-c26b-41e3-fbae-5636e5c91078"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model Predictions for a text that is tagged with the topic:\n"," [[{'label': 'LABEL_0', 'score': 0.0011187914060428739}, {'label': 'LABEL_1', 'score': 0.9988811612129211}]]\n","Model Predictions for a text that is NOT tagged with the topic:\n"," [[{'label': 'LABEL_0', 'score': 0.3649466931819916}, {'label': 'LABEL_1', 'score': 0.635053277015686}]]\n"]}],"source":["print(f'Model Predictions for a text that is tagged with the topic:\\n {berel_pipe(is_topic_text)}')\n","print(f'Model Predictions for a text that is NOT tagged with the topic:\\n {berel_pipe(is_not_topic_text)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iHQj4yTZuaDs","outputId":"2f4e4c12-7e3c-43c5-9edc-1b2ff9774c49"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model Predictions for a text that is tagged with the topic:\n"," [[{'label': 'LABEL_0', 'score': 0.0016728010959923267}, {'label': 'LABEL_1', 'score': 0.9983271956443787}]]\n","Model Predictions for a text that is NOT tagged with the topic:\n"," [[{'label': 'LABEL_0', 'score': 0.9907053112983704}, {'label': 'LABEL_1', 'score': 0.009294671006500721}]]\n"]}],"source":["print(f'Model Predictions for a text that is tagged with the topic:\\n {heBERT_pipe(is_topic_text)}')\n","print(f'Model Predictions for a text that is NOT tagged with the topic:\\n {heBERT_pipe(is_not_topic_text)}')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"0ZpzgjvXnza2"},"source":["As expected, all models predict that the related sentence is related to the topic and therefore LABEL_1 is high, and the opposite for the unrelated sentence.\n","\n","To try other texts, simply feed any string into `alephBERT_pipe`, `berel_pipe`, or `heBERT_pipe`"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"}},"nbformat":4,"nbformat_minor":0}
