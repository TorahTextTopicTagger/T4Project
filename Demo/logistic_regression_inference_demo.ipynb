{"cells":[{"cell_type":"markdown","metadata":{"id":"KT7v2kdUtgmo"},"source":["# Instructions"]},{"cell_type":"markdown","metadata":{"id":"QNYeuHxmtgmq"},"source":["This demo shows how you can load our logistic regression model for a given topic, define some example text to feed through the models, and see the inferences the model makes."]},{"cell_type":"markdown","metadata":{"id":"_MNPj3pAtgmr"},"source":["# Code"]},{"cell_type":"markdown","metadata":{"id":"yBWAfFsTtgmr"},"source":["## Loading Model"]},{"cell_type":"markdown","metadata":{"id":"7UFnxl_otgmr"},"source":["First, choose the topic you'd which the models will classify for (in this example we choose prayer -- \"תפילה\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c6AD5mAttgms"},"outputs":[],"source":["# CHOOSE YOUR TOPIC, options are ישראל, למוד, תורה, תפלה, תשובה\n","TOPIC = 'תפלה'"]},{"cell_type":"markdown","metadata":{"id":"dWN-QTh4tgmt"},"source":["Next we define the paths to the files we'll need for our models:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nwqy6tF4nf3V"},"outputs":[],"source":["def get_logistic_regression_model_path(topic):\n","  return f'../Models/Saved_Models/LogisticRegression/{topic}/'"]},{"cell_type":"markdown","metadata":{"id":"cxnZovn7tgmu"},"source":["And finally, we load the models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"notMwrzStgmu","outputId":"08883424-7712-484e-ee6b-ce683a2ed4d0"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator LogisticRegression from version 1.2.2 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n","https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n","  warnings.warn(\n","c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator CountVectorizer from version 1.2.2 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n","https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n","  warnings.warn(\n"]}],"source":["import pickle\n","\n","path = get_logistic_regression_model_path(TOPIC)\n","model = pickle.load(open(path+'model.pkl', 'rb'))\n","vectorizer = pickle.load(open(path+'vectorizer.pkl', 'rb'))"]},{"cell_type":"markdown","metadata":{"id":"_tUaWlN-tgmv"},"source":["## Inference"]},{"cell_type":"markdown","metadata":{"id":"a_cPf_-6tgmv"},"source":["Here you can define any text as a string to feed into the model. For this example, we choose one sentence that is highly correlated with the topic (it translates to \"standing before the Holy One Blessed be He, praying and calling out with all of one's heart about one's troubles\") and one sentence that is not at all correlated (it translates to \"it is nothing more than frivolity and light-headedness, and a son of Torah should not engage in these matters\").\n","\n","Note that for the related sentence, we choose a sentence that containד the topic's word, because otherwise the model isn't so good at picking up on the topic (as opposed to the transformer models)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G9f3dT6utgmw"},"outputs":[],"source":["is_topic_text = 'עומד לפני הקדוש ברוך הוא מתפלל וצועק בלב שלם על צרותיו'\n","is_not_topic_text = 'אין זה אלא שחוק וקלות ראש, ואין לבן תורה לעסוק בענינים אלו'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"28tyewXHtgmw"},"outputs":[],"source":["def infer_log_reg(text):\n","    text = vectorizer.transform([text])\n","    pred = model.predict(text)[0]\n","    prob = model.predict_proba(text)[0]\n","    return pred, prob"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VHcszAz3tgmw","outputId":"57ae3ef8-ecda-4f90-bdb7-014f744dfee6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted label: 1\n","Probabilities: [0.2075204 0.7924796]\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['באיזו', 'בו', 'במקום', 'בשעה', 'הסיבה', 'לאיזו', 'למקום', 'מאיזו', 'מידה', 'מקום', 'סיבה', 'שבגללה', 'שבו', 'תכלית'] not in stop_words.\n","  warnings.warn(\n"]}],"source":["pred, prob = infer_log_reg(is_topic_text)\n","print(f'Predicted label: {pred}\\nProbabilities: {prob}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mh-Xddv4tgmw","outputId":"9a7e9d23-24d1-4a42-ccb2-1a391d57a1be"},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted label: 0\n","Probabilities: [0.72580586 0.27419414]\n"]}],"source":["pred, prob = infer_log_reg(is_not_topic_text)\n","print(f'Predicted label: {pred}\\nProbabilities: {prob}')"]},{"cell_type":"markdown","metadata":{"id":"4FHqW4eztgmx"},"source":["As expected, the model predicts that the related sentence is related to the topic and therefore the prediction is 1 and the second probability is higher, and the opposite is true for the unrelated sentence.\n","\n","To try other texts, simply feed them into the `infer_log_reg` function. To test out a different topic, rerun the notebook with the `TOPIC` variable set differently."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"}},"nbformat":4,"nbformat_minor":0}